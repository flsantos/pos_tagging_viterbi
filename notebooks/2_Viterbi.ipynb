{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from collections import Counter\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_CETEN_v2.pkl', 'rb') as input:\n",
    "    phrases = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide a base em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_train , phrases_test = train_test_split(phrases,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converte qualquer palavra com freq < 5 para __RARE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_threshold = 5\n",
    "\n",
    "word_counts = Counter()\n",
    "for phrase in phrases_train:\n",
    "    for word in phrase:\n",
    "        word_counts[word[0]]+=1\n",
    "        \n",
    "word_counts = {word: count for word, count in word_counts.items() if word_counts[word] >= min_threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_train_rare = []\n",
    "RARE_WORD = '__RARE__'\n",
    "for phrase in phrases_train:\n",
    "    phrases_train_rare.append([(w[0] if word_counts.get(w[0]) else RARE_WORD,w[1]) for w in phrase])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contagem de palavras na base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counter = Counter()\n",
    "for s in phrases_train_rare:\n",
    "    for tk in s:\n",
    "        tag = tk[1]\n",
    "        if tags_counter[tag]:\n",
    "            tags_counter[tag]=tags_counter[tag]+1\n",
    "        else:\n",
    "            tags_counter[tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_tags = tags_counter.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contagem de etiquetas na base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for s in phrases_train_rare:\n",
    "    for tk in s:\n",
    "        if word_freq.get(tk[0]) == None:\n",
    "            word_freq[tk[0]] = Counter()\n",
    "        word_freq[tk[0]][tk[1]] = word_freq[tk[0]][tk[1]] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição da matriz de emissão (python dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_probs(word_freq, tags_counter):\n",
    "    smooth_emission_not_seen = 0\n",
    "    e = {}\n",
    "    for word in word_freq.keys():\n",
    "        for tag in tags_counter.keys():\n",
    "            if tags_counter[tag] == 0:\n",
    "                print(tag)\n",
    "            e[(word,tag)] = float((word_freq[word].get(tag,smooth_emission_not_seen)+1)/float(tags_counter[tag]))\n",
    "    return e\n",
    "e_prob = get_emission_probs(word_freq, tags_counter)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição da matriz de transição (python dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_transition_not_seen = 0\n",
    "\n",
    "def prep_sentence(phrase):\n",
    "    return ['*'] + ['*'] + [word[1] for word in phrase] + ['STOP']\n",
    "    \n",
    "def get_transition_probs(phrases,word_feq,tags_counter):\n",
    "\n",
    "    bigrams_c = Counter()\n",
    "    for phrase in phrases:\n",
    "        bigrams = nltk.bigrams(prep_sentence(phrase))\n",
    "        for bigram in bigrams:\n",
    "            bigrams_c[bigram] +=1\n",
    "\n",
    "    trigrams_c = Counter()\n",
    "    for phrase in phrases:\n",
    "        trigrams = nltk.trigrams(prep_sentence(phrase))\n",
    "        for trigram in trigrams:\n",
    "            trigrams_c[trigram] +=1\n",
    "\n",
    "    trigrams_p = {}\n",
    "    for trigram, trigram_count in trigrams_c.items():\n",
    "        bigram = (trigram[0],trigram[1])\n",
    "        bigram_count = bigrams_c.get(bigram)\n",
    "        if bigram_count:\n",
    "            trigrams_p[trigram] = float(trigram_count)/float(bigram_count)\n",
    "        else:\n",
    "            trigrams_p[trigram] = 0\n",
    "        \n",
    "    return trigrams_p, bigrams_c\n",
    "    \n",
    "    \n",
    "q_prob, bigrams_c = get_transition_probs(phrases,word_freq,tags_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1935931120449652"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "c = 0\n",
    "for w in word_freq.keys():\n",
    "    for k in allowed_tags:\n",
    "        #e_prob[(w,k)]\n",
    "        c=c+1\n",
    "print(c)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sents, e_prob,q_prob,allowed_tags, tdef, tloop1, tloop2, ttag):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    \n",
    "    def S(k):\n",
    "        if k == -1 or k == 0:\n",
    "            return ['*']\n",
    "        else:\n",
    "            return allowed_tags\n",
    "    pi = {}\n",
    "    pi[(0, '*','*')] = 1\n",
    "\n",
    "    bp = {}\n",
    "    \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    tdef=tdef+elapsed\n",
    "    #print(\"Time definition: \", elapsed)\n",
    "\n",
    "    tagged = []\n",
    "    for sent in sents:\n",
    "        c=0\n",
    "        start_time = timeit.default_timer()\n",
    "        for k in range(1, len(sent)+1):\n",
    "            for u in S(k-1):\n",
    "                for v in S(k):\n",
    "                    max_p = -1\n",
    "                    max_tag = None\n",
    "                    for w in S(k-2):\n",
    "                        c=c+1\n",
    "                        #if bigrams_c[(w,u)] > 0: ### Se o bigram não existir na base de treino, não faz sentido testá-lo aqui \n",
    "                        prob = pi[(k-1,w,u)] * q_prob.get((w,u,v),0) * e_prob[(sent[k-1],v)]\n",
    "                        #prob = 0\n",
    "                        if (prob > max_p):\n",
    "                            max_p = prob\n",
    "                            max_tag = w\n",
    "                    pi[(k,u,v)] = max_p\n",
    "                    bp[(k,u,v)] = max_tag\n",
    "\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        tloop1+=elapsed\n",
    "        #print(\"First loop: \", elapsed)\n",
    "        #print(c)\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        max_p = -1\n",
    "        max_u_tag = None\n",
    "        max_v_tag = None\n",
    "        n = len(sent)\n",
    "        for u in S(n-1):\n",
    "            for v in S(n):\n",
    "                #if bigrams_c[(u,v)] > 0:\n",
    "                prob = pi[(n,u,v)] * q_prob.get((u,v,'STOP'),0)\n",
    "                if (prob > max_p):\n",
    "                    max_p = prob\n",
    "                    max_u_tag = u\n",
    "                    max_v_tag = v\n",
    "\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        tloop2+=elapsed\n",
    "        #print(\"Second loop: \", elapsed)\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        tags = []\n",
    "        tags.append(max_v_tag)\n",
    "        tags.append(max_u_tag)\n",
    "        for i,k in enumerate(range(n-2,0, -1)):\n",
    "            tags.append(bp[(k+2, tags[i+1], tags[i])])\n",
    "\n",
    "        tags = list(reversed(tags))\n",
    "\n",
    "        tagged_sentence = []\n",
    "        for j in range(0, n):\n",
    "            tagged_sentence.append((sent[j], tags[j]))\n",
    "\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        ttag+=elapsed\n",
    "        #print(\"Tags: \", elapsed)\n",
    "        \n",
    "        tagged.append(tagged_sentence)\n",
    "    \n",
    "    return tagged, tdef, tloop1, tloop2, ttag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdef=0\n",
    "tloop1=0\n",
    "tloop2=0\n",
    "ttag=0\n",
    "corretas_baseline = 0\n",
    "corretas_viterbi = 0\n",
    "totais = 0\n",
    "\n",
    "testwith = 10000\n",
    "for s in phrases_test[:testwith]:\n",
    "    sents_with_rare = []\n",
    "    sents_with_rare.append([tk[0] if word_counts.get(tk[0]) != None else RARE_WORD for tk in s])\n",
    "    preds,tdef, tloop1, tloop2, ttag = viterbi(sents_with_rare, e_prob, q_prob, allowed_tags, tdef, tloop1, tloop2, ttag)\n",
    "    for tk_golden, tk_pred in zip(s,preds[0]):\n",
    "        totais+=1\n",
    "        if tk_golden[1] == word_freq[tk_pred[0]].most_common(1)[0][0]:\n",
    "            corretas_baseline+=1\n",
    "        if tk_golden[1] == tk_pred[1]:\n",
    "            corretas_viterbi+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.985253611111111"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases_test)*0.053/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008938368179087774,\n",
       " 53.887110182648826,\n",
       " 0.128611268689383,\n",
       " 0.017564173378048054)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdef, tloop1, tloop2, ttag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15405, 15173, 15989, 96.3474888986178, 94.89649133779473)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretas_viterbi, corretas_baseline, totais, corretas_viterbi/totais*100, corretas_baseline/totais*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tdef=0\n",
    "tloop1=0\n",
    "tloop2=0\n",
    "ttag=0\n",
    "corretas_baseline = 0\n",
    "corretas_viterbi = 0\n",
    "totais = 0\n",
    "sents_with_rare = []\n",
    "\n",
    "testwith = 1000\n",
    "for s in phrases_test[:testwith]:\n",
    "    sents_with_rare.append([tk[0] if word_counts.get(tk[0]) != None else RARE_WORD for tk in s])\n",
    "\n",
    "preds,tdef, tloop1, tloop2, ttag = viterbi(sents_with_rare, e_prob, q_prob, allowed_tags, tdef, tloop1, tloop2, ttag)\n",
    "for s_golden, s_pred in zip(phrases_test[:testwith],preds):\n",
    "    for tk_golden, tk_pred in zip(s_golden,s_pred):\n",
    "        totais+=1\n",
    "        if tk_golden[1] == word_freq[tk_pred[0]].most_common(1)[0][0]:\n",
    "            corretas_baseline+=1\n",
    "        if tk_golden[1] == tk_pred[1]:\n",
    "            corretas_viterbi+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15405, 15173, 15989, 96.3474888986178, 94.89649133779473)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretas_viterbi, corretas_baseline, totais, corretas_viterbi/totais*100, corretas_baseline/totais*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.332559517981281e-06,\n",
       " 52.36434300194827,\n",
       " 0.12211555686576503,\n",
       " 0.017630418069131792)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdef, tloop1, tloop2, ttag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 504, 530, 94.52830188679245, 95.09433962264151)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretas_viterbi, corretas_baseline, totais, corretas_viterbi/totais*100, corretas_baseline/totais*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.245258369905969e-05,\n",
       " 25.797425600680697,\n",
       " 0.02671713703517753,\n",
       " 0.0009236935800345236)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdef, tloop1, tloop2, ttag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 504, 530, 94.52830188679245, 95.09433962264151)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretas_viterbi, corretas_baseline, totais, corretas_viterbi/totais*100, corretas_baseline/totais*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "viterbi() missing 1 required positional argument: 'e_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-292-90df57efb38b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#phrase = 'ele caiu de a escada e morreu em a hora'.split(' ')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mphrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mRARE_WORD\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphrases_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mviterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: viterbi() missing 1 required positional argument: 'e_values'"
     ]
    }
   ],
   "source": [
    "#phrase = 'ele caiu de a escada e morreu em a hora'.split(' ')\n",
    "phrase = [tk[0] if word_counts.get(tk[0]) != None else RARE_WORD for tk in phrases_test[0]]\n",
    "viterbi(phrase, e_prob, q_prob, allowed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "START_SYMBOL = '*'\n",
    "STOP_SYMBOL = 'STOP'\n",
    "RARE_SYMBOL = '__RARE__'\n",
    "\n",
    "def viterbi(brown_dev_words, taglist, known_words, q_values, e_values):\n",
    "    tagged = []\n",
    "\n",
    "    # pi[(k, u, v)]: max probability of a tag sequence ending in tags u, v at position k\n",
    "    # bp[(k, u, v)]: backpointers to recover the argmax of pi[(k, u, v)]\n",
    "    pi = defaultdict(float)\n",
    "    bp = {}\n",
    "\n",
    "    # Initialization\n",
    "    pi[(0, START_SYMBOL, START_SYMBOL)] = 1\n",
    "\n",
    "    # Define tagsets S(k)\n",
    "    def S(k):\n",
    "        if k in (-1, 0):\n",
    "            return {START_SYMBOL}\n",
    "        else:\n",
    "            return taglist\n",
    "\n",
    "    # The Viterbi algorithm\n",
    "    for sent_words_actual in brown_dev_words:\n",
    "        sent_words = [word if word in known_words else RARE_SYMBOL for word in sent_words_actual]\n",
    "        n = len(sent_words)\n",
    "        for k in range(1, n+1):\n",
    "            for u in S(k-1):\n",
    "                for v in S(k):\n",
    "                    max_score = -1\n",
    "                    max_tag = None\n",
    "                    for w in S(k - 2):\n",
    "                        #if e_values.get((sent_words[k-1], v), 0) != 0:\n",
    "                        score = pi[(k-1, w, u)] * \\\n",
    "                                q_values.get((w, u, v),0) * \\\n",
    "                                e_values[(sent_words[k-1], v)]\n",
    "                        if score > max_score:\n",
    "                            max_score = score\n",
    "                            max_tag = w\n",
    "                    pi[(k, u, v)] = max_score\n",
    "                    bp[(k, u, v)] = max_tag\n",
    "\n",
    "        max_score = -1\n",
    "        u_max, v_max = None, None\n",
    "        for u in S(n-1):\n",
    "            for v in S(n):\n",
    "                score = pi[(n, u, v)] * \\\n",
    "                        q_values.get((u, v, STOP_SYMBOL), 0)\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    u_max = u\n",
    "                    v_max = v\n",
    "\n",
    "        tags = []\n",
    "        tags.append(v_max)\n",
    "        tags.append(u_max)\n",
    "\n",
    "        for i, k in enumerate(range(n-2, 0, -1)):\n",
    "            tags.append(bp[(k+2, tags[i+1], tags[i])])\n",
    "        tags = list(reversed(tags))\n",
    "\n",
    "        tagged_sentence = []\n",
    "        for j in range(0, n):\n",
    "            tagged_sentence.append((sent_words_actual[j] , tags[j]))\n",
    "        tagged.append(tagged_sentence)\n",
    "        \n",
    "\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 530)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr = [list(map(lambda x: x[0], ph)) for ph in phrases_test[:30]]\n",
    "phrases_viterbi = viterbi(phr, allowed_tags, set(word_counts.keys()), q_prob, e_prob)\n",
    "\n",
    "corretas = 0\n",
    "totais = 0\n",
    "for s_viterbi, s_gold in zip(phrases_viterbi, phrases_test[:30]):\n",
    "    for tk_viterbi, tk_gold in zip(s_viterbi, s_gold):\n",
    "        totais+=1\n",
    "        if tk_gold[1] == tk_viterbi[1]:\n",
    "            corretas+=1\n",
    "corretas,totais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
